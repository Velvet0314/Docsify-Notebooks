<!-- _sidebar.md -->

* [前言](README.md)
- [第一章&ensp;机器学习入门](note1/Part1.md)
  - [机器学习的定义](note1/Part1.md?id=机器学习的定义)
  - [机器学习的分类](note1/Part1.md?id=机器学习的分类)
    - [监督学习](note1/Part1.md?id=监督学习)
    - [无监督学习](note1/Part1.md?id=无监督学习)
* [第二章&ensp;线性回归](note2/Part2.md)
  * [LMS Algorithm](note2/Part2.md?id=LMS-Algorithm)
    * [批量梯度下降](note2/Part2.md?id=批量梯度下降)
    * [随机梯度下降](note2/Part2.md?id=随机梯度下降)
    * [⭐小结：LMS](note2/Part2.md?id=⭐小结-LMS)
      * [BGD 与 SGD 的区别](note2/Part2.md?id=BGD-与-SGD-的区别)
      * [SGD 与 学习率衰减](note2/Part2.md?id=SGD-与-学习率衰减)
  * [Normal Equation](note2/Part2.md?id=Normal-Equation)
    * [数学准备](note2/Part2.md?id=数学准备)
      * [矩阵求导入门](note2/Part2.md?id=矩阵求导入门)
      * [矩阵的迹](note2/Part2.md?id=矩阵的迹)
      * [⭐迹的性质](note2/Part2.md?id=⭐迹的性质)
      * [⭐方程推导](note2/Part2.md?id=⭐方程推导)
  * [概率解释](note2/Part2.md?id=概率解释)
  * [局部加权线性回归](note2/Part2.md?id=局部加权线性回归)
    * [过拟合与欠拟合](note2/Part2.md?id=过拟合与欠拟合)
    * [LWLR 的定义](note2/Part2.md?id=LWLR-的定义)
- [第三章&ensp;二分类](note3/Part3.md)
  - [⭐逻辑回归](note3/Part3.md?id=⭐逻辑回归)
    - [总结：逻辑回归](note3/Part3.md?id=总结：逻辑回归)
  - [感知机](note3/Part3.md?id=感知机)
  - [牛顿法](note3/Part3.md?id=牛顿法)
* [第四章&ensp;广义线性模型](note4/Part4.md)
  * [指数族](note4/Part4.md?id=指数族)
  * [GLM 的构建](note4/Part4.md?id=GLM-的构建)
    * [最小二乘法](note4/Part4.md?id=最小二乘法)
    * [逻辑回归](note4/Part4.md?id=逻辑回归)
    * [⭐Softmax 回归](note4/Part4.md?id=⭐Softmax-回归)
      * [类比推广](note4/Part4.md?id=类比推广)
      * [验证并构建 GLM](note4/Part4.md?id=验证并构建-GLM)
      * [参数估计](note4/Part4.md?id=参数估计)
- [第五章&ensp;生成学习算法](note5/Part5.md)
  - [高斯判别分析](note5/Part5.md?id=高斯判别分析)
    - [数学准备](note5/Part5.md?id=数学准备)
    - [多元正态分布*](note5/Part5.md?id=多元正态分布)
    - [GDA 模型](note5/Part5.md?id=GDA-模型)
    - [Extra: GDA 与 逻辑回归](note5/Part5.md?id=extra-gda-与-逻辑回归)
  - [朴素贝叶斯](note5/Part5.md?id=朴素贝叶斯)
    - [高斯判别分析](note5/Part5.md?id=高斯判别分析)
    - [NB 假设](note5/Part5.md?id=NB-假设)
    - [特征向量离散化](note5/Part5.md?id=特征向量离散化)
    - [拉普拉斯平滑](note5/Part5.md?id=拉普拉斯平滑)
    - [文本分类的事件模型*](note5/Part5.md?id=文本分类的事件模型)
* [第六章&ensp;支持向量机](note6/Part6.md)
  * [边界：直观感受](note6/Part6.md?id=边界-直观感受)
  * [SVM 定义](note6/Part6.md?id=SVM-定义)
  * [边界](note6/Part6.md?id=边界)
    * [函数边界](note6/Part6.md?id=函数边界)
    * [几何边界](note6/Part6.md?id=几何边界)
  * [拉格朗日对偶](note6/Part6.md?id=拉格朗日对偶)
    * [数学准备](note6/Part6.md?id=数学准备)
      * [函数的凹凸性](note6/Part6.md?id=函数的凹凸性)
        * [凸函数](note6/Part6.md?id=凸函数)
        * [凹函数](note6/Part6.md?id=凹函数)
      * [无约束的优化问题](note6/Part6.md?id=无约束的优化问题)
      * [带有等式约束的优化问题](note6/Part6.md?id=带有等式约束的优化问题)
      * [拉格朗日乘数法](note6/Part6.md?id=拉格朗日乘数法)
      * [仿射函数](note6/Part6.md?id=仿射函数)
      * [凸优化](note6/Part6.md?id=凸优化)
      * [对偶问题](note6/Part6.md?id=对偶问题)
        * [线性规划](note6/Part6.md?id=线性规划)
        * [问题定义](note6/Part6.md?id=问题定义)
    * [定义](note6/Part6.md?id=定义)
    * [对偶强弱](note6/Part6.md?id=对偶强弱)
      * [弱对偶](note6/Part6.md?id=弱对偶)
      * [强对偶](note6/Part6.md?id=强对偶)
    * [KKT 条件](note6/Part6.md?id=KKT-条件)
  * [最优边界决策器](note6/Part6.md?id=最优边界决策器)
  * [核 Kernel](note6/Part6.md?id=核-Kernel)
  * [正则化](note6/Part6.md?id=正则化)
  * [SMO 算法](note6/Part6.md?id=SMO-算法)
    * [坐标上升](note6/Part6.md?id=坐标上升)
    * [SMO 详解](note6/Part6.md?id=SMO-详解)
* [第七章&ensp;学习理论](note7/Part7.md)
  * [偏差/方差权衡](note7/Part7.md?id=偏差-方差权衡)
  * [知识准备](note7/Part7.md?id=知识准备)
    * [切尔诺夫界](note7/Part7.md?id=切尔诺夫界)
    * [经验风险最小化](note7/Part7.md?id=经验风险最小化)
  * [有限假设类 <span class="math">$\small{\mathcal{H}}$</span>](note7/Part7.md?id=有限假设类-largemathcalh-)
  * [无限假设类 <span class="math">$\small{\mathcal{H}}$</span>](note7/Part7.md?id=无限假设类-largemathcalmathcalh-)
    * [VC 维](note7/Part7.md?id=VC-维)
* [第八章&ensp;正则化与模型选择](note8/Part8.md)
  * [交叉验证](note8/Part8.md?id=交叉验证)
  * [特征选择](note8/Part8.md?id=特征选择)
  * [贝叶斯统计与正则化*](note8/Part8.md?id=贝叶斯统计与正则化)
* [第九章&ensp;EM 算法](note9/Part9.md)
  * [高斯混合模型](note9/Part9.md?id=高斯混合模型)
  * [EM 算法](note9/Part9.md?id=EM-算法)
  * [Jensen 不等式](note9/Part9.md?id=Jensen-不等式)
  * [EM 算法推广](note9/Part9.md?id=EM-算法推广)
  * [高斯混合模型](note9/Part9.md?id=高斯混合模型)
* [第十章&ensp;因子分析](note10/Part10.md)
  * [<span class="math">$\small{\Sigma}$</span> 的约束条件](note10/Part10.md?id=largesigma-的约束条件)
  * [多重高斯模型](note10/Part10.md?id=多重高斯模型)
  * [因子分析模型](note10/Part10.md?id=因子分析模型)
* [第十一章&ensp;PCA 主成分分析](note11/Part11.md)
* [第十二章&ensp;ICA 独立成分分析](note12/Part12.md)
  * [ICA 的模糊性](note12/Part12.md?id=ICA-的模糊性)
  * [密度和线性变换](note12/Part12.md?id=密度和线性变换)
  * [ICA 算法](note12/Part12.md?id=ICA-算法)
* [第十三章&ensp;强化学习](note13/Part13.md)
  * [马尔可夫决策过程](note13/Part13.md?id=马尔可夫决策过程)
  * [值迭代和策略迭代](note13/Part13.md?id=值迭代和策略迭代)
  * [MDPs 的模型构建](note13/Part13.md?id=MDPs-的模型构建)
  * [连续状态的 MDPs](note13/Part13.md?id=连续状态的-MDPs)
    * [离散化](note13/Part13.md?id=离散化)
    * [值函数近似](note13/Part13.md?id=值函数近似)
      * [使用一个模型或模拟器](note13/Part13.md?id=使用一个模型或模拟器)
      * [拟合值迭代](note13/Part13.md?id=拟合值迭代)
* [Experience 心得](experience/experience.md)
