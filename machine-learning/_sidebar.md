<!-- _sidebar.md -->

* [前言](/machine-learning/README.md)
- [第一章&ensp;机器学习入门](/machine-learning/note1/Part1.md)
  - [机器学习的定义](/machine-learning/note1/Part1.md?id=机器学习的定义)
  - [机器学习的分类](/machine-learning/note1/Part1.md?id=机器学习的分类)
    - [监督学习](/machine-learning/note1/Part1.md?id=监督学习)
    - [无监督学习](/machine-learning/note1/Part1.md?id=无监督学习)
* [第二章&ensp;线性回归](/machine-learning/note2/Part2.md)
  * [LMS Algorithm](/machine-learning/note2/Part2.md?id=LMS-Algorithm)
    * [批量梯度下降](/machine-learning/note2/Part2.md?id=批量梯度下降)
    * [随机梯度下降](/machine-learning/note2/Part2.md?id=随机梯度下降)
    * [⭐小结：LMS](/machine-learning/note2/Part2.md?id=⭐小结-LMS)
      * [BGD 与 SGD 的区别](/machine-learning/note2/Part2.md?id=BGD-与-SGD-的区别)
      * [SGD 与 学习率衰减](/machine-learning/note2/Part2.md?id=SGD-与-学习率衰减)
  * [Normal Equation](/machine-learning/note2/Part2.md?id=Normal-Equation)
    * [数学准备](/machine-learning/note2/Part2.md?id=数学准备)
      * [矩阵求导入门](/machine-learning/note2/Part2.md?id=矩阵求导入门)
      * [矩阵的迹](/machine-learning/note2/Part2.md?id=矩阵的迹)
      * [⭐迹的性质](/machine-learning/note2/Part2.md?id=⭐迹的性质)
      * [⭐方程推导](/machine-learning/note2/Part2.md?id=⭐方程推导)
  * [概率解释](/machine-learning/note2/Part2.md?id=概率解释)
  * [局部加权线性回归](/machine-learning/note2/Part2.md?id=局部加权线性回归)
    * [过拟合与欠拟合](machine-learning/note2/Part2.md?id=过拟合与欠拟合)
    * [LWLR 的定义](/machine-learning/note2/Part2.md?id=LWLR-的定义)
- [第三章&ensp;二分类](/machine-learning//machine-learning/note3/Part3.md)
  - [⭐逻辑回归](/machine-learning/note3/Part3.md?id=⭐逻辑回归)
    - [总结：逻辑回归](/machine-learning//machine-learning/note3/Part3.md?id=总结：逻辑回归)
  - [感知机](/machine-learning/note3/Part3.md?id=感知机)
  - [牛顿法](/machine-learning/note3/Part3.md?id=牛顿法)
* [第四章&ensp;广义线性模型](/machine-learning//machine-learning/note4/Part4.md)
  * [指数族](/machine-learning/note4/Part4.md?id=指数族)
  * [GLM 的构建](/machine-learning/note4/Part4.md?id=GLM-的构建)
    * [最小二乘法](/machine-learning/note4/Part4.md?id=最小二乘法)
    * [逻辑回归](/machine-learning/note4/Part4.md?id=逻辑回归)
    * [⭐Softmax 回归](/machine-learning/note4/Part4.md?id=⭐Softmax-回归)
      * [类比推广](/machine-learning/note4/Part4.md?id=类比推广)
      * [验证并构建 GLM](/machine-learning/note4/Part4.md?id=验证并构建-GLM)
      * [参数估计](/machine-learning/note4/Part4.md?id=参数估计)
- [第五章&ensp;生成学习算法](/machine-learning/note5/Part5.md)
  - [高斯判别分析](/machine-learning/note5/Part5.md?id=高斯判别分析)
    - [数学准备](/machine-learning/note5/Part5.md?id=数学准备)
    - [多元正态分布*](/machine-learning/note5/Part5.md?id=多元正态分布)
    - [GDA 模型](/machine-learning//machine-learning/note5/Part5.md?id=GDA-模型)
    - [Extra: GDA 与 逻辑回归](/machine-learning/note5/Part5.md?id=extra-gda-与-逻辑回归)
  - [朴素贝叶斯](/machine-learning/note5/Part5.md?id=朴素贝叶斯)
    - [高斯判别分析](/machine-learning/note5/Part5.md?id=高斯判别分析)
    - [NB 假设](/machine-learning/note5/Part5.md?id=NB-假设)
    - [特征向量离散化](/machine-learning/note5/Part5.md?id=特征向量离散化)
    - [拉普拉斯平滑](/machine-learning/note5/Part5.md?id=拉普拉斯平滑)
    - [文本分类的事件模型*](/machine-learning/note5/Part5.md?id=文本分类的事件模型)
* [第六章&ensp;支持向量机](/machine-learning/note6/Part6.md)
  * [边界：直观感受](/machine-learning/note6/Part6.md?id=边界-直观感受)
  * [SVM 定义](/machine-learning/Part6.md?id=SVM-定义)
  * [边界](/machine-learning//machine-learning/note6/Part6.md?id=边界)
    * [函数边界](/machine-learning/note6/Part6.md?id=函数边界)
    * [几何边界](/machine-learning/note6/Part6.md?id=几何边界)
  * [拉格朗日对偶](/machine-learning/note6/Part6.md?id=拉格朗日对偶)
    * [数学准备](/machine-learning/note6/Part6.md?id=数学准备)
      * [函数的凹凸性](/machine-learning/note6/Part6.md?id=函数的凹凸性)
        * [凸函数](/machine-learning/note6/Part6.md?id=凸函数)
        * [凹函数](/machine-learning/note6/Part6.md?id=凹函数)
      * [无约束的优化问题](/machine-learning/note6/Part6.md?id=无约束的优化问题)
      * [带有等式约束的优化问题](/machine-learning/note6/Part6.md?id=带有等式约束的优化问题)
      * [拉格朗日乘数法](/machine-learning/note6/Part6.md?id=拉格朗日乘数法)
      * [仿射函数](/machine-learning/note6/Part6.md?id=仿射函数)
      * [凸优化](/machine-learning/note6/Part6.md?id=凸优化)
      * [对偶问题](/machine-learning/note6/Part6.md?id=对偶问题)
        * [线性规划](/machine-learning/note6/Part6.md?id=线性规划)
        * [问题定义](/machine-learning/note6/Part6.md?id=问题定义)
    * [定义](/machine-learning/note6/Part6.md?id=定义)
    * [对偶强弱](/machine-learning/note6/Part6.md?id=对偶强弱)
      * [弱对偶](/machine-learning/note6/Part6.md?id=弱对偶)
      * [强对偶](/machine-learning/note6/Part6.md?id=强对偶)
    * [KKT 条件](/machine-learning/note6/Part6.md?id=KKT-条件)
  * [最优边界决策器](/machine-learning/note6/Part6.md?id=最优边界决策器)
  * [核 Kernel](/machine-learning/note6/Part6.md?id=核-Kernel)
  * [正则化](/machine-learning/note6/Part6.md?id=正则化)
  * [SMO 算法](/machine-learning/note6/Part6.md?id=SMO-算法)
    * [坐标上升](/machine-learning/note6/Part6.md?id=坐标上升)
    * [SMO 详解](/machine-learning/note6/Part6.md?id=SMO-详解)
* [第七章&ensp;学习理论](/machine-learning/note7/Part7.md)
  * [偏差/方差权衡](/machine-learning/note7/Part7.md?id=偏差-方差权衡)
  * [知识准备](/machine-learning/note7/Part7.md?id=知识准备)
    * [切尔诺夫界](/machine-learning/note7/Part7.md?id=切尔诺夫界)
    * [经验风险最小化](/machine-learning/note7/Part7.md?id=经验风险最小化)
  * [有限假设类 <span class="math">$\small{\mathcal{H}}$</span>](/machine-learning/note7/Part7.md?id=有限假设类-largemathcalh-)
  * [无限假设类 <span class="math">$\small{\mathcal{H}}$</span>](/machine-learning/note7/Part7.md?id=无限假设类-largemathcalmathcalh-)
    * [VC 维](/machine-learning/note7/Part7.md?id=VC-维)
* [第八章&ensp;正则化与模型选择](/machine-learning/note8/Part8.md)
  * [交叉验证](/machine-learning/note8/Part8.md?id=交叉验证)
  * [特征选择](/machine-learning/note8/Part8.md?id=特征选择)
  * [贝叶斯统计与正则化*](/machine-learning/note8/Part8.md?id=贝叶斯统计与正则化)
* [第九章&ensp;EM 算法](/machine-learning/note9/Part9.md)
  * [高斯混合模型](/machine-learning/note9/Part9.md?id=高斯混合模型)
  * [EM 算法](/machine-learning/note9/Part9.md?id=EM-算法)
  * [Jensen 不等式](/machine-learning/note9/Part9.md?id=Jensen-不等式)
  * [EM 算法详解](/machine-learning/note9/Part9.md?id=EM-算法详解)
  * [高斯混合模型详解](/machine-learning/note9/Part9.md?id=高斯混合模型详解)
* [第十章&ensp;因子分析](/machine-learning/note10/Part10.md)
  * [<span class="math">$\small{\Sigma}$</span> 的约束条件](/machine-learning/note10/Part10.md?id=largesigma-的约束条件)
  * [多重高斯模型的边缘分布与条件分布](/machine-learning/note10/Part10.md?id=多重高斯模型的边缘分布与条件分布)
  * [因子分析模型](/machine-learning/note10/Part10.md?id=因子分析模型)
  * [适用于因子分析的 EM 算法](/machine-learning/note10/Part10.md?id=适用于因子分析的-EM-算法)
* [第十一章&ensp;PCA 主成分分析](/machine-learning/note11/Part11.md)
* [第十二章&ensp;ICA 独立成分分析](/machine-learning/note12/Part12.md)
  * [ICA 的模糊性](/machine-learning/note12/Part12.md?id=ICA-的模糊性)
  * [密度和线性变换](/machine-learning/note12/Part12.md?id=密度和线性变换)
  * [ICA 算法](/machine-learning/note12/Part12.md?id=ICA-算法)
* [第十三章&ensp;强化学习](/machine-learning/note13/Part13.md)
  * [马尔可夫决策过程](/machine-learning/note13/Part13.md?id=马尔可夫决策过程)
  * [值迭代和策略迭代](/machine-learning/note13/Part13.md?id=值迭代和策略迭代)
  * [MDPs 的模型构建](/machine-learning/note13/Part13.md?id=MDPs-的模型构建)
  * [连续状态的 MDPs](/machine-learning/note13/Part13.md?id=连续状态的-MDPs)
    * [离散化](/machine-learning/note13/Part13.md?id=离散化)
    * [值函数近似](/machine-learning/note13/Part13.md?id=值函数近似)
      * [使用一个模型或模拟器](/machine-learning/note13/Part13.md?id=使用一个模型或模拟器)
      * [拟合值迭代](/machine-learning/note13/Part13.md?id=拟合值迭代)
